{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from encodec.seanet import SEANetEncoder, SEANetDecoder\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.sparse import csgraph\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BabySlakhDataset(Dataset):\n",
    "    def __init__(self, data_dir, sample_rate=44100, normalize=True):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.filepaths = list(self.data_dir.glob(\"*.wav\"))\n",
    "        self.sample_rate = sample_rate\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fpath = self.filepaths[idx]\n",
    "        waveform, sr = torchaudio.load(fpath)\n",
    "\n",
    "        if sr != self.sample_rate:\n",
    "            resampler = T.Resample(sr, self.sample_rate)\n",
    "\n",
    "        if self.normalize:\n",
    "            max_val = waveform.abs().max()\n",
    "            if max_val > 0:\n",
    "                waveform = waveform / max_val\n",
    "        return waveform, fpath.name \n",
    "    \n",
    "data_dir = \"musdb18_others\"\n",
    "dataset = BabySlakhDataset(data_dir, sample_rate=44100, normalize=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barbo\\Desktop\\AML-\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\.venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "C:\\Users\\barbo\\AppData\\Local\\Temp\\ipykernel_32520\\2317712128.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(r\"C:\\Users\\barbo\\Desktop\\AML-\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\best_model_long2.pth\\best_model_long2.pth\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from epoch 24 with loss 0.1882\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ratios = [4, 4, 4, 2]\n",
    "encoder = SEANetEncoder(channels=2, dimension=512, n_filters=48, ratios=ratios).to(device)\n",
    "decoder = SEANetDecoder(channels=2, dimension=512, n_filters=48, ratios=ratios, final_activation='Tanh').to(device)\n",
    "\n",
    "#checkpoint = torch.load(\"best_model_long2.pth\", map_location=device)\n",
    "checkpoint = torch.load(r\"C:\\Users\\barbo\\Desktop\\AML-\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\best_model_long2.pth\\best_model_long2.pth\", map_location=device)\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']} with loss {checkpoint['loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed combined track saved as processed_combined_song.wav\n"
     ]
    }
   ],
   "source": [
    "# Find ground truth, and mix them together to create a new track\n",
    "# Try separation on the new track and compare with the ground truth\n",
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "import torch\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "file1 = r\"C:\\Users\\barbo\\Desktop\\AML-\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\110_F_AcousticGuitar_03_724.wav\"\n",
    "file2 = r\"C:\\Users\\barbo\\Desktop\\AML-\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\110_F_Lofipiano_SP_10_406.wav\"\n",
    "\n",
    "target_duration = 6.8  \n",
    "sample_rate = 44100 \n",
    "output_file = \"processed_combined_song.wav\"\n",
    "\n",
    "def preprocess_audio(file_path, target_duration, sample_rate):\n",
    "    waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "    if sr != sample_rate:\n",
    "        resampler = Resample(sr, sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Truncate or pad the waveform to target duration\n",
    "    num_samples = int(target_duration * sample_rate)\n",
    "    if waveform.size(1) > num_samples:\n",
    "        # Truncate\n",
    "        waveform = waveform[:, :num_samples]\n",
    "    else:\n",
    "        # Pad\n",
    "        padding = num_samples - waveform.size(1)\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "\n",
    "    return waveform\n",
    "\n",
    "# Preprocess both tracks\n",
    "waveform1 = preprocess_audio(file1, target_duration, sample_rate)\n",
    "waveform2 = preprocess_audio(file2, target_duration, sample_rate)\n",
    "\n",
    "# Combine the two waveforms\n",
    "combined_waveform = waveform1 + waveform2\n",
    "\n",
    "# Normalize the combined waveform to prevent clipping\n",
    "max_val = combined_waveform.abs().max()\n",
    "if max_val > 0:\n",
    "    combined_waveform = combined_waveform / max_val\n",
    "\n",
    "# Convert to s16 (16-bit PCM)\n",
    "combined_waveform = (combined_waveform * 32767).short()\n",
    "sf.write(output_file, combined_waveform.numpy().T, sample_rate, subtype=\"PCM_16\", format=\"WAV\")\n",
    "print(f\"Processed combined track saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total downsampling factor is 4*4*4*2 = 128 for SEANet with the given ratios.\n",
    "TOTAL_DOWNSAMPLE = 128\n",
    "sample_rate = 44100\n",
    "\n",
    "def pad_to_multiple(waveform: torch.Tensor, multiple: int):\n",
    "    \"\"\"\n",
    "    Pad waveform (B x C x T) with zeros so that T is a multiple of 'multiple'.\n",
    "    Returns padded_waveform, num_padded\n",
    "    \"\"\"\n",
    "    b, c, t = waveform.shape\n",
    "    remainder = t % multiple\n",
    "    if remainder == 0:\n",
    "        return waveform, 0\n",
    "    pad_amount = multiple - remainder\n",
    "    padded = nn.functional.pad(waveform, (0, pad_amount))\n",
    "    return padded, pad_amount\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in dataloader:\n",
    "        waveform, sample_rate, fname, _ = batch_data\n",
    "        waveform = waveform.to(device)  # (B=1, C, T)\n",
    "\n",
    "        # If mono, duplicating to stereo\n",
    "        if waveform.shape[1] == 1:\n",
    "            waveform = waveform.repeat(1, 2, 1)\n",
    "\n",
    "        # 1) Pading so that the encoder/decoder reconstructs the full length\n",
    "        padded_waveform, pad_amount = pad_to_multiple(waveform, TOTAL_DOWNSAMPLE)\n",
    "\n",
    "        # 2) Encoding to latent\n",
    "        z = encoder(padded_waveform)  # shape: (B=1, feat_dim=512, T_down)\n",
    "        # Rearranging to (B * T_down, feat_dim) for clustering\n",
    "        z_flat = z.permute(0, 2, 1).reshape(-1, z.shape[1])  # (B*T_down, 512)\n",
    "\n",
    "        # 3) Constructing a similarity matrix\n",
    "        #    Typical spectral clustering uses L = D - A or normalized Laplacian\n",
    "        #    but for demonstration we still build from rbf and then compute L.\n",
    "        z_flat_norm = normalize(z_flat.cpu().numpy())  # shape (N, 512)\n",
    "        gamma = 0.1 \n",
    "        # RBF kernel\n",
    "        dist_sq = sklearn.metrics.pairwise.euclidean_distances(z_flat_norm, squared=True)\n",
    "        similarity_matrix = np.exp(-gamma * dist_sq)\n",
    "\n",
    "        # Building the normalized Laplacian for standard spectral clustering\n",
    "        # L = D^(-1/2) (D - A) D^(-1/2)\n",
    "        # We'll use scipy's built-in function: csgraph.laplacian\n",
    "        laplacian, diag = csgraph.laplacian(similarity_matrix, normed=True, return_diag=True)\n",
    "\n",
    "        # 4) Choosing the number of clusters k\n",
    "        #    There are many ways to choose k. Here are two common approaches:\n",
    "        #    Option A: Using an eigengap heuristic on the *smallest* eigenvalues of L\n",
    "        #    Option B: Trying k in [2..max_clusters], and picking the best silhouette.\n",
    "        max_clusters = 4\n",
    "        possible_ks = range(2, max_clusters+1)\n",
    "\n",
    "        # (A) Eigen-decomposing the normalized Laplacian\n",
    "        #     We want the SMALLEST k eigenvalues (which='SM')\n",
    "        #     The largest dimension we need is max_clusters.\n",
    "        #     the 0th eigenvalue is often 0 with multiplicity of at least 1.\n",
    "        w, v = eigsh(laplacian, k=max_clusters, which='SM')  # shape of w: (max_clusters,)\n",
    "\n",
    "        # The eigenvalues w are in ascending order. The largest gap among w[0..max_clusters-1].\n",
    "        # This is a common heuristic for choosing the number of clusters.\n",
    "        #   w_sorted = np.sort(w)\n",
    "        #   we compute gaps in consecutive sorted eigenvalues: w[i+1] - w[i]\n",
    "        #   then pick i that yields the largest gap => i+1 clusters\n",
    "        w_sorted = np.sort(w)\n",
    "        #gaps = w_sorted[1:] - w_sorted[:-1]  # length max_clusters-1\n",
    "        #best_k_gap = np.argmax(gaps) + 1\n",
    "\n",
    "        # After w_sorted = np.sort(w):\n",
    "        skip_first = 1  # often the smallest eigenvalue is near 0 \n",
    "        w_skip = w_sorted[skip_first:]  # ignoring the first eigenvalue\n",
    "        gaps = w_skip[1:] - w_skip[:-1]\n",
    "        best_k_gap_idx = np.argmax(gaps)\n",
    "        best_k_gap = best_k_gap_idx + 1 + skip_first  # +1 for 1-based index, +skip_first offset\n",
    "        best_k_gap = max(2, min(best_k_gap, max_clusters))  # clamp in [2, max_clusters]\n",
    "\n",
    "\n",
    "\n",
    "        # (B) Alternative: silhouette-based approach:\n",
    "        # silhouette_scores = []\n",
    "        # for test_k in possible_ks:\n",
    "        #     sc = SpectralClustering(n_clusters=test_k, affinity=\"precomputed\", random_state=42)\n",
    "        #     test_labels = sc.fit_predict(similarity_matrix)\n",
    "        #     score = silhouette_score(z_flat_norm, test_labels)\n",
    "        #     silhouette_scores.append(score)\n",
    "        # best_k_silhouette = possible_ks[np.argmax(silhouette_scores)]\n",
    "\n",
    "        num_clusters = best_k_gap\n",
    "        print(f\"[{fname}] - best_k_gap = {best_k_gap} (raw eigenvalues: {w_sorted})\")\n",
    "\n",
    "        # 5) Running spectral clustering with the chosen k\n",
    "        spectral = SpectralClustering(\n",
    "            n_clusters=num_clusters,\n",
    "            affinity=\"precomputed\",\n",
    "            random_state=42,\n",
    "        )\n",
    "        cluster_labels = spectral.fit_predict(similarity_matrix)  # shape (N,)\n",
    "\n",
    "        # Reshaping cluster_labels to (B=1, T_down)\n",
    "        # We had z.shape = (1, 512, T_down), so N = T_down for a single batch\n",
    "        cluster_labels = torch.tensor(cluster_labels, device=device).view(z.shape[0], z.shape[2])  # (B=1, T_down)\n",
    "\n",
    "        # 6) Building masks and decode each cluster\n",
    "        separated_sources = []\n",
    "        for cluster_id in range(num_clusters):\n",
    "            mask = (cluster_labels == cluster_id).float()  # shape (B=1, T_down)\n",
    "            mask = mask.unsqueeze(1)  # (B=1, 1, T_down)\n",
    "            z_masked = z * mask  # (B=1, 512, T_down)\n",
    "            # Decoding\n",
    "            separated_source = decoder(z_masked, input_length=padded_waveform.shape[-1])  # shape (B=1, C=2, T)\n",
    "            # Removing the extra pad at the end if we added any\n",
    "            if pad_amount > 0:\n",
    "                separated_source = separated_source[..., :-pad_amount]\n",
    "            separated_sources.append(separated_source)\n",
    "\n",
    "        output_root = Path(\"separated_sources\")\n",
    "        output_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # 7) Saving separated sources\n",
    "        for i, source in enumerate(separated_sources):\n",
    "            out_path = output_root / f\"{fname}_source_{i}.wav\"\n",
    "            # Squeeze batch dim -> (C, T)\n",
    "            torchaudio.save(out_path, source.squeeze(0).cpu(), sample_rate=sample_rate)\n",
    "            print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster a single song:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import csgraph\n",
    "from mir_eval.separation import bss_eval_sources\n",
    "from pathlib import Path\n",
    "\n",
    "TOTAL_DOWNSAMPLE = 128\n",
    "sample_rate = 44100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mixture_file = \"processed_combined_song.wav\"\n",
    "original_sources = [\"original_stem1.wav\", \"original_stem2.wav\"]\n",
    "\n",
    "def pad_to_multiple(waveform: torch.Tensor, multiple: int):\n",
    "    b, c, t = waveform.shape\n",
    "    remainder = t % multiple\n",
    "    if remainder == 0:\n",
    "        return waveform, 0\n",
    "    pad_amount = multiple - remainder\n",
    "    padded = nn.functional.pad(waveform, (0, pad_amount))\n",
    "    return padded, pad_amount\n",
    "\n",
    "def preprocess_audio(file_path, target_sample_rate, duration=None):\n",
    "    waveform, sr = torchaudio.load(file_path)\n",
    "    if sr != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sr, target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "    if duration is not None:\n",
    "        num_samples = int(target_sample_rate * duration)\n",
    "        if waveform.shape[1] > num_samples:\n",
    "            waveform = waveform[:, :num_samples]\n",
    "        else:\n",
    "            waveform = nn.functional.pad(waveform, (0, num_samples - waveform.shape[1]))\n",
    "    return waveform\n",
    "\n",
    "waveform = preprocess_audio(mixture_file, sample_rate).unsqueeze(0).to(device)\n",
    "\n",
    "if waveform.shape[1] == 1:\n",
    "    waveform = waveform.repeat(1, 2, 1)\n",
    "\n",
    "padded_waveform, pad_amount = pad_to_multiple(waveform, TOTAL_DOWNSAMPLE)\n",
    "\n",
    "z = encoder(padded_waveform)  # shape: (B=1, feat_dim=512, T_down)\n",
    "z_flat = z.permute(0, 2, 1).reshape(-1, z.shape[1])  # (B*T_down, 512)\n",
    "\n",
    "z_flat_norm = normalize(z_flat.detach().cpu().numpy())\n",
    "gamma = 0.1\n",
    "dist_sq = sklearn.metrics.pairwise.euclidean_distances(z_flat_norm, squared=True)\n",
    "similarity_matrix = np.exp(-gamma * dist_sq)\n",
    "\n",
    "laplacian, _ = csgraph.laplacian(similarity_matrix, normed=True, return_diag=True)\n",
    "\n",
    "w, _ = eigsh(laplacian, k=4, which=\"SM\")\n",
    "num_clusters = max(2, np.argmax(np.diff(w[1:])) + 2)  # Skip trivial eigenvalue\n",
    "spectral = SpectralClustering(n_clusters=num_clusters, affinity=\"precomputed\", random_state=42)\n",
    "cluster_labels = spectral.fit_predict(similarity_matrix)\n",
    "\n",
    "cluster_labels = torch.tensor(cluster_labels, device=device).view(z.shape[0], z.shape[2])\n",
    "separated_sources = []\n",
    "for cluster_id in range(num_clusters):\n",
    "    mask = (cluster_labels == cluster_id).float().unsqueeze(1)\n",
    "    z_masked = z * mask\n",
    "    separated_source = decoder(z_masked, input_length=padded_waveform.shape[-1])\n",
    "    if pad_amount > 0:\n",
    "        separated_source = separated_source[..., :-pad_amount]\n",
    "    separated_sources.append(separated_source)\n",
    "\n",
    "output_root = Path(\"separated_sources\")\n",
    "output_root.mkdir(exist_ok=True, parents=True)\n",
    "for i, source in enumerate(separated_sources):\n",
    "    out_path = output_root / f\"source_{i}.wav\"\n",
    "    source_int16 = (source.squeeze(0).detach().cpu() * 32767).type(torch.int16)\n",
    "    torchaudio.save(out_path, source_int16, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDR: [-4.09080358], SIR: [inf], SAR: [-4.09080358]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "\n",
    "ref, sr = librosa.load('110_F_AcousticGuitar_03_724.wav', sr=None)\n",
    "est, _ = librosa.load(r\"C:\\Users\\barbo\\Desktop\\AML-\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\Music-Source-Separation-for-an-Additional-Instrument-encodec\\separated_sources\\source_0.wav\", sr=None)\n",
    "\n",
    "ref_sources = np.stack([ref], axis=0)\n",
    "est_sources = np.stack([est], axis=0)\n",
    "\n",
    "sdr, sir, sar, _ = mir_eval.separation.bss_eval_sources(ref_sources, est_sources)\n",
    "\n",
    "print(f\"SDR: {sdr}, SIR: {sir}, SAR: {sar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "MAX_SECONDS = 5  \n",
    "SR = 44100 \n",
    "\n",
    "output_root = Path(\"latent_separation_eigengap\")\n",
    "output_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def build_latent_similarity(z_np, alpha=2, rbf_sigma=None):\n",
    "    \"\"\"\n",
    "    Construct NxN similarity matrix from latent frames z_np.\n",
    "      z_np.shape => (latent_channels, latent_length)\n",
    "    We'll interpret each 'time step' in the latent domain as a vector in R^(latent_channels).\n",
    "    \n",
    "    - We optionally apply an RBF kernel with sigma=rbf_sigma.\n",
    "    - Then, we do a final normalization step so that the matrix is <= 1.0\n",
    "    - Output: similarity_matrix (NxN), distance_matrix (NxN).\n",
    "    \"\"\"\n",
    "    # Transpose => shape (N, D) with N=latent_length, D=latent_channels\n",
    "    z_T = z_np.T  # shape => (N, D)\n",
    "    N, D = z_T.shape\n",
    "    \n",
    "    # dist_mat[i,j] = ||z_T[i] - z_T[j]||^2\n",
    "    diffs = z_T[:, None, :] - z_T[None, :, :]  # shape => (N, N, D)\n",
    "    dist_mat_sq = np.sum(diffs**2, axis=-1)    # shape => (N, N)\n",
    "    \n",
    "    if rbf_sigma is None:\n",
    "        median_dist = np.median(dist_mat_sq)\n",
    "        if median_dist < 1e-12:\n",
    "            median_dist = 1.0\n",
    "        rbf_sigma = np.sqrt(median_dist)\n",
    "    \n",
    "    # RBF kernel => sim[i,j] = exp(-||z_i - z_j||^2 / (2*sigma^2))\n",
    "    sim = np.exp(-dist_mat_sq / (2 * (rbf_sigma**2)))\n",
    "    \n",
    "    if alpha != 1:\n",
    "        sim = sim**alpha\n",
    "\n",
    "    max_val = sim.max()\n",
    "    if max_val > 1.0:\n",
    "        sim = sim / (max_val + 1e-12)\n",
    "\n",
    "    dist = -np.log(sim + 1e-12)\n",
    "    dist = np.clip(dist, 0, None)\n",
    "    np.fill_diagonal(dist, 0.0)\n",
    "    \n",
    "    return sim, dist\n",
    "\n",
    "\n",
    "class spectral_clustering_eigengap:\n",
    "    \"\"\"\n",
    "    Spectral clustering with eigengap. \n",
    "    This is analogous to your 'spectral_clustering' class,\n",
    "    but we don't need partial-based Laplacian from STFT.\n",
    "    We'll directly build L from the NxN adjacency 'A' (the similarity matrix).\n",
    "    \"\"\"\n",
    "    def __init__(self, similarity_matrix):\n",
    "        self.A = similarity_matrix \n",
    "        self.D = np.diag(np.sum(self.A, axis=1))\n",
    "        self.L = self.D - self.A\n",
    "        self.eigen_vals, self.eigen_vecs = linalg.eigh(self.L, self.D)\n",
    "\n",
    "    def get_k(self):\n",
    "        \"\"\"\n",
    "        Use the largest eigengap to pick the number of clusters.\n",
    "        \"\"\"\n",
    "        eigen_vals = self.eigen_vals\n",
    "        n = len(eigen_vals)\n",
    "        max_gap = 0.0\n",
    "        k = 1\n",
    "        for i in range(n - 1):\n",
    "            gap = abs(eigen_vals[i + 1] - eigen_vals[i])\n",
    "            if gap > max_gap:\n",
    "                max_gap = gap\n",
    "                k = i + 1\n",
    "        print(\"eigengap heuristic suggests:\", k)\n",
    "        return k\n",
    "\n",
    "    def fit(self, k=None):\n",
    "        \"\"\"\n",
    "        Cluster via KMeans on the top-k eigenvectors of L (skipping index=0).\n",
    "        \"\"\"\n",
    "        if k is None:\n",
    "            k = self.get_k()\n",
    "\n",
    "        X = self.eigen_vecs[:, 1 : (1 + k)]\n",
    "\n",
    "        X_normed = normalize(X, norm='l2')\n",
    "        \n",
    "        pred_label = KMeans(n_clusters=k, random_state=42).fit_predict(X_normed)\n",
    "        return pred_label\n",
    "\n",
    "\n",
    "def cluster_latent_dbscan(dist_matrix, eps=0.5, min_samples=5, max_clusters=4):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN in the latent domain, but forcibly ensure\n",
    "    the final # of clusters <= max_clusters by merging if needed.\n",
    "    \n",
    "    - dist_matrix: NxN distance matrix\n",
    "    - eps, min_samples: DBSCAN hyperparams\n",
    "    - max_clusters: if #clusters > this, we do a naive merging approach.\n",
    "    \"\"\"\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "    labels = db.fit_predict(dist_matrix)\n",
    "    \n",
    "    unique_l = np.unique(labels)\n",
    "    positives = [u for u in unique_l if u >= 0]\n",
    "    if len(positives) > max_clusters:\n",
    "        print(f\"DBSCAN found {len(positives)} clusters, merging to {max_clusters} ...\")\n",
    "        positives_sorted = sorted(positives)\n",
    "        keep = positives_sorted[: (max_clusters - 1)]\n",
    "        merge_rest = positives_sorted[(max_clusters - 1) : ]\n",
    "\n",
    "        new_labels = labels.copy()\n",
    "        for i in range(len(new_labels)):\n",
    "            lab = new_labels[i]\n",
    "            if lab in keep:\n",
    "                pass\n",
    "            elif lab in merge_rest:\n",
    "                new_labels[i] = keep[-1] \n",
    "        labels = new_labels\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in dataloader:\n",
    "        waveform, fname = batch_data\n",
    "        if isinstance(fname, (list, tuple)):\n",
    "            fname = fname[0]\n",
    "\n",
    "        waveform = waveform.to(\"cpu\")\n",
    "\n",
    "        if waveform.shape[1] == 1:\n",
    "            waveform = waveform.repeat(1, 2, 1)\n",
    "\n",
    "        wave_len = waveform.shape[-1]\n",
    "        max_samples = SR * MAX_SECONDS\n",
    "        if wave_len > max_samples:\n",
    "            waveform = waveform[..., :max_samples]\n",
    "\n",
    "        z = encoder(waveform)  \n",
    "        z_np = z.squeeze(0).cpu().numpy()  \n",
    "\n",
    "        similarity_matrix, distance_matrix = build_latent_similarity(z_np, alpha=1.0, rbf_sigma=None)\n",
    "\n",
    "        print(f\"\\n=== Processing {fname} ===\")\n",
    "        print(f\"latent shape: {z_np.shape}, similarity_matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "        sc = spectral_clustering_eigengap(similarity_matrix)\n",
    "        k_estimated = sc.get_k()\n",
    "        labels_spectral = sc.fit(k=k_estimated)\n",
    "\n",
    "        labels = labels_spectral\n",
    "\n",
    "        unique_labels = np.unique(labels)\n",
    "        n_clusters = sum(u >= 0 for u in unique_labels)\n",
    "        print(f\"Clusters found: {n_clusters} (eigengap => k={k_estimated})\")\n",
    "\n",
    "        separated_signals = []\n",
    "        positives = [u for u in unique_labels if u >= 0] \n",
    "        for c_id in positives:\n",
    "            z_masked = np.zeros_like(z_np)\n",
    "            z_masked[:, labels == c_id] = z_np[:, labels == c_id]\n",
    "\n",
    "            z_masked_torch = torch.from_numpy(z_masked).unsqueeze(0).float()\n",
    "            z_masked_torch = z_masked_torch.to(waveform.device)\n",
    "\n",
    "            separated_decoded = decoder(z_masked_torch)\n",
    "            separated_audio = separated_decoded.squeeze(0).cpu().numpy()\n",
    "            separated_signals.append(separated_audio)\n",
    "\n",
    "        out_folder = output_root / fname\n",
    "        out_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i, audio_c in enumerate(separated_signals):\n",
    "            out_path = out_folder / f\"cluster_{i}.wav\"\n",
    "            sf.write(str(out_path), audio_c.T, SR)\n",
    "        \n",
    "        print(f\"Saved {len(separated_signals)} clusters to '{out_folder}'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_cluster_entropy(\n",
    "    separated_signals,\n",
    "    sample_rate=44100,\n",
    "    n_fft=1024,\n",
    "    hop_length=512\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the Shannon entropy of frequency distribution for each separated signal.\n",
    "\n",
    "    Arguments:\n",
    "        separated_signals (List[torch.Tensor]):\n",
    "            - Each tensor is shape [C, T] or [T] (mono). \n",
    "            - If multi-channel, we'll just pick one channel or average channels.\n",
    "        sample_rate (int): Audio sample rate (not mandatory, but can be useful if you'd like\n",
    "                           to adapt window sizes based on sample rate).\n",
    "        n_fft (int): Number of FFT bins.\n",
    "        hop_length (int): STFT hop length (window shift).\n",
    "\n",
    "    Returns:\n",
    "        entropies (List[float]): One entropy value per signal in `separated_signals`.\n",
    "    \"\"\"\n",
    "    entropies = []\n",
    "\n",
    "    for idx, sig in enumerate(separated_signals):\n",
    "        if sig.dim() == 2:\n",
    "            sig = sig[0]  \n",
    "\n",
    "        stft_out = torch.stft(\n",
    "            sig, \n",
    "            n_fft=n_fft, \n",
    "            hop_length=hop_length, \n",
    "            window=None, \n",
    "            center=True, \n",
    "            normalized=False, \n",
    "            onesided=True, \n",
    "            return_complex=True\n",
    "        )\n",
    "        mag = stft_out.abs() \n",
    "        freq_sum = mag.sum(dim=1)\n",
    "\n",
    "        total_energy = freq_sum.sum()\n",
    "        if total_energy < 1e-12:\n",
    "            entropies.append(0.0)\n",
    "            continue\n",
    "\n",
    "        p_f = freq_sum / total_energy\n",
    "        p_f = torch.clamp(p_f, min=1e-12)\n",
    "        H = - (p_f * torch.log2(p_f)).sum()\n",
    "\n",
    "        entropies.append(H.item())\n",
    "\n",
    "    return entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def compute_cluster_sparsity(\n",
    "    separated_signals,\n",
    "    sample_rate=44100,\n",
    "    n_fft=1024,\n",
    "    hop_length=512\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute spectral sparsity for each separated signal using Hoyer's measure.\n",
    "\n",
    "    Arguments:\n",
    "        separated_signals (List[torch.Tensor]):\n",
    "            - Each tensor is shape [C, T] or [T] (mono).\n",
    "        sample_rate (int): Audio sample rate (not strictly needed, but kept for consistency).\n",
    "        n_fft (int): Number of FFT bins.\n",
    "        hop_length (int): STFT hop length (window shift).\n",
    "\n",
    "    Returns:\n",
    "        sparsities (List[float]): One sparsity value per signal in 'separated_signals'.\n",
    "    \"\"\"\n",
    "    sparsities = []\n",
    "\n",
    "    for sig in separated_signals:\n",
    "        if sig.dim() == 2:\n",
    "            sig = sig[0] \n",
    "\n",
    "        stft_out = torch.stft(\n",
    "            sig,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            window=None,\n",
    "            center=True,\n",
    "            normalized=False,\n",
    "            onesided=True,\n",
    "            return_complex=True  \n",
    "        )\n",
    "        mag = stft_out.abs() \n",
    "        freq_sum = mag.sum(dim=1) \n",
    "        n = freq_sum.shape[0]\n",
    "\n",
    "        if freq_sum.sum() < 1e-12:\n",
    "            sparsities.append(0.0)\n",
    "            continue\n",
    "\n",
    "        l1 = freq_sum.sum().item()                     \n",
    "        l2 = freq_sum.norm(2).item()                   \n",
    "        sqrt_n = math.sqrt(n)\n",
    "\n",
    "        hoyer_num = sqrt_n - (l1 / l2)\n",
    "        hoyer_den = sqrt_n - 1.0\n",
    "\n",
    "        sparsity_val = max(0.0, min(hoyer_num / hoyer_den, 1.0))\n",
    "        sparsities.append(sparsity_val)\n",
    "\n",
    "    return sparsities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_energy_distribution(separated_signals, mixture):\n",
    "    \"\"\"\n",
    "    Compute energy distribution of separated sources relative to the total mixture energy.\n",
    "\n",
    "    Args:\n",
    "        separated_signals (List[torch.Tensor]):\n",
    "            Each is shape [channels, time] or [time].\n",
    "        mixture (torch.Tensor):\n",
    "            The original mixture, shape [channels, time] or [time].\n",
    "\n",
    "    Returns:\n",
    "        energy_ratios (List[float]):\n",
    "            Each ratio = (energy of cluster i) / (energy of mixture).\n",
    "        sum_of_ratios (float):\n",
    "            Sum of all cluster ratios, ideally ~1.0 if energy is preserved.\n",
    "        total_mix_energy (float):\n",
    "            Energy of the mixture, for reference.\n",
    "    \"\"\"\n",
    "    if mixture.dim() == 2:\n",
    "        total_mix_energy = mixture.pow(2).sum().item()\n",
    "    else:\n",
    "        total_mix_energy = mixture.pow(2).sum().item()\n",
    "\n",
    "    if total_mix_energy < 1e-12:\n",
    "        n_signals = len(separated_signals)\n",
    "        return [0.0] * n_signals, 0.0, 0.0\n",
    "\n",
    "    energy_ratios = []\n",
    "    for sig in separated_signals:\n",
    "        if sig.dim() == 2:\n",
    "            E_i = sig.pow(2).sum().item()\n",
    "        else:\n",
    "            E_i = sig.pow(2).sum().item()\n",
    "\n",
    "        ratio = E_i / total_mix_energy\n",
    "        energy_ratios.append(ratio)\n",
    "\n",
    "    sum_of_ratios = sum(energy_ratios)\n",
    "\n",
    "    return energy_ratios, sum_of_ratios, total_mix_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_spectrograms(mixture, separated_signals, sample_rate=44100, n_fft=1024, hop_length=512):\n",
    "    \"\"\"\n",
    "    Plot the spectrogram of `mixture` and each separated signal in subplots.\n",
    "    \n",
    "    Args:\n",
    "        mixture (torch.Tensor): shape [C, T] or [T].\n",
    "        separated_signals (List[torch.Tensor]]): each shape [C, T] or [T].\n",
    "        sample_rate (int): for display\n",
    "        n_fft (int): STFT size\n",
    "        hop_length (int): hop length\n",
    "    \"\"\"\n",
    "    if mixture.dim() == 2:\n",
    "        mix_mono = mixture[0, :]  \n",
    "    else:\n",
    "        mix_mono = mixture\n",
    "\n",
    "    total_plots = 1 + len(separated_signals)\n",
    "    fig, axs = plt.subplots(total_plots, 1, figsize=(8, 2 * total_plots))\n",
    "    \n",
    "    axs[0].set_title(\"Mixture Spectrogram\")\n",
    "    mixture_stft = torch.stft(\n",
    "        mix_mono, \n",
    "        n_fft=n_fft, \n",
    "        hop_length=hop_length, \n",
    "        window=None, \n",
    "        center=True,\n",
    "        onesided=True,\n",
    "        return_complex=True \n",
    "    )\n",
    "    mix_mag = mixture_stft.abs().cpu().numpy()  \n",
    "    axs[0].imshow(20 * np.log10(mix_mag + 1e-6), aspect='auto', origin='lower')\n",
    "    axs[0].set_ylabel(\"Frequency Bin\")\n",
    "    \n",
    "    for i, sig in enumerate(separated_signals, start=1):\n",
    "        if sig.dim() == 2:\n",
    "            sig_mono = sig[0, :]\n",
    "        else:\n",
    "            sig_mono = sig\n",
    "\n",
    "        stft_out = torch.stft(\n",
    "            sig_mono, \n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            window=None,\n",
    "            center=True,\n",
    "            onesided=True,\n",
    "            return_complex=True\n",
    "        )\n",
    "        mag = stft_out.abs().cpu().numpy()\n",
    "        \n",
    "        axs[i].imshow(20 * np.log10(mag + 1e-6), aspect='auto', origin='lower')\n",
    "        axs[i].set_title(f\"Source {i} Spectrogram\")\n",
    "        axs[i].set_ylabel(\"Frequency Bin\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spla\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "def compute_laplacian(data, sigma=1.0, mode='rbf'):\n",
    "    dist = pairwise_distances(data, data, metric='euclidean')\n",
    "    if mode == 'rbf':\n",
    "        W = np.exp(-dist**2 / (2.0 * sigma**2))\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only RBF kernel is implemented.\")\n",
    "    d = np.sum(W, axis=1)\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(d + 1e-12))\n",
    "    W_tilde = D_inv_sqrt @ W @ D_inv_sqrt\n",
    "    L = np.eye(W.shape[0]) - W_tilde\n",
    "    return L\n",
    "\n",
    "def spectral_embedding_eigengap(data, k_max=5, sigma=1.0, maxiter=3000, tol=1e-3):\n",
    "    \"\"\"\n",
    "    Return a spectral embedding (dim chosen by largest eigen-gap).\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    if N <= k_max:\n",
    "        return data\n",
    "\n",
    "    L = compute_laplacian(data, sigma=sigma, mode='rbf')\n",
    "    L_sparse = sp.csr_matrix(L)\n",
    "\n",
    "    try:\n",
    "        eigenvals, eigenvects = spla.eigsh(\n",
    "            L_sparse, k=k_max+1, which='SM',\n",
    "            maxiter=maxiter, tol=tol,\n",
    "            ncv=min(2*(k_max+1), N)\n",
    "        )\n",
    "    except spla.ArpackNoConvergence as e:\n",
    "        print(f\"[WARNING] ARPACK failed to converge: {e}\")\n",
    "        return data\n",
    "\n",
    "    idx_sorted = np.argsort(eigenvals)\n",
    "    eigenvals = eigenvals[idx_sorted]\n",
    "    eigenvects = eigenvects[:, idx_sorted]\n",
    "\n",
    "    lam_nontrivial = eigenvals[1:]\n",
    "    gaps = np.diff(lam_nontrivial)\n",
    "    i_gap = np.argmax(gaps)\n",
    "    chosen_dim = i_gap + 1\n",
    "    chosen_dim = max(2, min(chosen_dim, k_max))\n",
    "\n",
    "    embedding = eigenvects[:, 1:1+chosen_dim]\n",
    "    return embedding\n",
    "\n",
    "def auto_kmeans(X, k_min=2, k_max=5):\n",
    "    \"\"\"\n",
    "    Try KMeans for k in [k_min..k_max], pick the k with the highest silhouette score.\n",
    "    Return (best_labels, best_k).\n",
    "    \"\"\"\n",
    "    best_k = k_min\n",
    "    best_score = -1\n",
    "    best_labels = None\n",
    "\n",
    "    for k in range(k_min, k_max + 1):\n",
    "        km = KMeans(n_clusters=k, random_state=0)\n",
    "        labels = km.fit_predict(X)\n",
    "\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) < 2:\n",
    "            continue\n",
    "\n",
    "        score = silhouette_score(X, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_labels = labels\n",
    "\n",
    "    if best_labels is None:\n",
    "        km = KMeans(n_clusters=k_min, random_state=0)\n",
    "        best_labels = km.fit_predict(X)\n",
    "        best_k = k_min\n",
    "\n",
    "    return best_labels, best_k\n",
    "\n",
    "def subsample_latent(z_t, max_frames=3000):\n",
    "    \"\"\"\n",
    "    Optional: Subsample the latent space data to reduce frames.\n",
    "    \"\"\"\n",
    "    T_enc = z_t.shape[0]\n",
    "    if T_enc > max_frames:\n",
    "        idxs = np.linspace(0, T_enc - 1, max_frames, dtype=int)\n",
    "        z_t = z_t[idxs]\n",
    "    return z_t\n",
    "\n",
    "output_root = Path(\"separated_sources\")\n",
    "output_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in dataloader:\n",
    "        waveform, fname = batch_data\n",
    "        if isinstance(fname, (list, tuple)):\n",
    "            fname = fname[0]\n",
    "\n",
    "        print(\"\\n=============================================\")\n",
    "        print(f\"[INFO] Processing file: {fname}\")\n",
    "\n",
    "        waveform = waveform.to(device)\n",
    "        if waveform.shape[1] == 1:\n",
    "            waveform = waveform.repeat(1, 2, 1)\n",
    "\n",
    "        z = encoder(waveform)  \n",
    "        print(f\"  [DEBUG] Encoded shape: {z.shape}\")\n",
    "\n",
    "        z_t = z.squeeze(0).permute(1, 0).cpu().numpy()  \n",
    "        print(f\"  [DEBUG] Flattened shape: {z_t.shape}\")\n",
    "\n",
    "        z_t = subsample_latent(z_t, max_frames=3000)\n",
    "        print(f\"  [DEBUG] After subsampling: {z_t.shape}\")\n",
    "\n",
    "        embedded = spectral_embedding_eigengap(\n",
    "            z_t, k_max=5, sigma=1.0, maxiter=5000, tol=1e-2\n",
    "        )\n",
    "        print(\"  [DEBUG] Spectral embedding complete.\")\n",
    "\n",
    "        labels, chosen_k = auto_kmeans(embedded, k_min=2, k_max=5)\n",
    "        print(f\"[INFO] K-MEANS => final cluster count = {chosen_k}\")\n",
    "\n",
    "        out_dir = output_root / Path(fname).stem\n",
    "        out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        z_original = z.clone()\n",
    "        T_sub = embedded.shape[0]\n",
    "        T_full = z_original.shape[-1]\n",
    "        \n",
    "        unique_labels = sorted(set(labels))\n",
    "\n",
    "        full_mask = torch.zeros((1, 1, T_full), dtype=torch.float, device=device)\n",
    "        cluster_index = 1\n",
    "        for c_label in unique_labels:\n",
    "            idx_c = np.where(labels == c_label)[0]\n",
    "            mask = full_mask.clone()\n",
    "            for i_c in idx_c:\n",
    "                if i_c < T_full:\n",
    "                    mask[0, 0, i_c] = 1.0\n",
    "\n",
    "            z_masked = z_original * mask\n",
    "            separated_waveform = decoder(z_masked).squeeze(0)\n",
    "\n",
    "            out_path = out_dir / f\"source_{cluster_index}.wav\"\n",
    "            torchaudio.save(str(out_path), separated_waveform.cpu(), 44100)\n",
    "            print(f\"  [DEBUG] Saved cluster_{cluster_index} (label={c_label}) -> {out_path}\")\n",
    "            cluster_index += 1\n",
    "\n",
    "        entropies = compute_cluster_entropy(separated_signals, sample_rate=44100)\n",
    "        sparsities = compute_cluster_sparsity(separated_signals, sample_rate=44100)\n",
    "\n",
    "        for i, (H, S) in enumerate(zip(entropies, sparsities), start=1):\n",
    "            print(f\"[INFO] Cluster {i} Entropy: {H:.4f} | Sparsity: {S:.4f}\")\n",
    "\n",
    "        energy_ratios, sum_of_ratios, total_mix_energy = compute_energy_distribution(separated_signals, mix)\n",
    "\n",
    "        print(f\"\\n[INFO] Energy Distribution for {fname}:\")\n",
    "        print(f\"  Mixture energy = {total_mix_energy:.2f}\")\n",
    "        for i, ratio in enumerate(energy_ratios, start=1):\n",
    "            print(f\"  Cluster {i} => {ratio*100:.2f}% of mixture energy\")\n",
    "        print(f\"  Sum of ratios = {sum_of_ratios:.3f} (ideally ~1.0)\")\n",
    "\n",
    "        visualize_spectrograms(mix, separated_signals, sample_rate=44100)\n",
    "\n",
    "        print(f\"[INFO] Done with {fname}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative clustering\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spla\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_laplacian(data, sigma=1.0, mode='rbf'):\n",
    "    \"\"\"\n",
    "    Compute the normalized Laplacian using an RBF kernel.\n",
    "    \"\"\"\n",
    "    dist = pairwise_distances(data, data, metric='euclidean')\n",
    "\n",
    "    if mode == 'rbf':\n",
    "        W = np.exp(-dist**2 / (2.0 * sigma**2))\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only RBF kernel is implemented.\")\n",
    "\n",
    "    d = np.sum(W, axis=1)\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(d + 1e-12))\n",
    "    W_tilde = D_inv_sqrt @ W @ D_inv_sqrt\n",
    "\n",
    "    # Normalized Laplacian: L = I - D^(-1/2) * W * D^(-1/2)\n",
    "    L = np.eye(W.shape[0]) - W_tilde\n",
    "    return L\n",
    "\n",
    "\n",
    "def spectral_embedding_eigengap(data, k_max=5, sigma=1.0, maxiter=3000, tol=1e-3):\n",
    "    \"\"\"\n",
    "    Compute the spectral embedding for 'data', choosing embedding dimension\n",
    "    via the largest eigengap among the smallest (k_max+1) eigenvalues.\n",
    "    Returns the embedded data of shape [N, chosen_dim].\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    if N <= k_max:\n",
    "        return data\n",
    "\n",
    "    L = compute_laplacian(data, sigma=sigma, mode='rbf')\n",
    "    L_sparse = sp.csr_matrix(L)\n",
    "\n",
    "    try:\n",
    "        eigenvals, eigenvects = spla.eigsh(\n",
    "            L_sparse, k=k_max + 1, which='SM',\n",
    "            maxiter=maxiter, tol=tol,\n",
    "            ncv=min(2*(k_max+1), N)\n",
    "        )\n",
    "    except spla.ArpackNoConvergence as e:\n",
    "        print(f\"[WARNING] ARPACK failed to converge: {e}\")\n",
    "        return data\n",
    "\n",
    "    idx_sorted = np.argsort(eigenvals)\n",
    "    eigenvals = eigenvals[idx_sorted]\n",
    "    eigenvects = eigenvects[:, idx_sorted]\n",
    "\n",
    "    lam_nontrivial = eigenvals[1:]\n",
    "    gaps = np.diff(lam_nontrivial)\n",
    "    i_gap = np.argmax(gaps)\n",
    "    chosen_dim = i_gap + 1\n",
    "    chosen_dim = max(2, min(chosen_dim, k_max))\n",
    "\n",
    "    embedding = eigenvects[:, 1:1 + chosen_dim]\n",
    "    return embedding\n",
    "\n",
    "def auto_agglomerative(X, k_min=2, k_max=5):\n",
    "    \"\"\"\n",
    "    Try AgglomerativeClustering for k in [k_min..k_max],\n",
    "    pick the k with the highest silhouette score.\n",
    "    Returns (best_labels, best_k).\n",
    "    \"\"\"\n",
    "    best_k = k_min\n",
    "    best_score = -1\n",
    "    best_labels = None\n",
    "\n",
    "    for k in range(k_min, k_max + 1):\n",
    "        agg = AgglomerativeClustering(n_clusters=k)\n",
    "        labels = agg.fit_predict(X)\n",
    "\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) < 2:\n",
    "            continue\n",
    "\n",
    "        score = silhouette_score(X, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_labels = labels\n",
    "\n",
    "    if best_labels is None:\n",
    "        agg = AgglomerativeClustering(n_clusters=k_min)\n",
    "        best_labels = agg.fit_predict(X)\n",
    "        best_k = k_min\n",
    "\n",
    "    return best_labels, best_k\n",
    "\n",
    "def subsample_latent(z_t, max_frames=3000):\n",
    "    \"\"\"\n",
    "    Downsample the time dimension to <= max_frames.\n",
    "    \"\"\"\n",
    "    T_enc = z_t.shape[0]\n",
    "    if T_enc > max_frames:\n",
    "        idxs = np.linspace(0, T_enc - 1, max_frames, dtype=int)\n",
    "        z_t = z_t[idxs]\n",
    "    return z_t\n",
    "\n",
    "output_root = Path(\"separated_sources\")\n",
    "output_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in dataloader:\n",
    "        waveform, fname = batch_data\n",
    "        if isinstance(fname, (list, tuple)):\n",
    "            fname = fname[0]\n",
    "\n",
    "        print(\"\\n=============================================\")\n",
    "        print(f\"[INFO] Processing file: {fname}\")\n",
    "\n",
    "        waveform = waveform.to(device)\n",
    "        if waveform.shape[1] == 1:\n",
    "            waveform = waveform.repeat(1, 2, 1)\n",
    "\n",
    "        z = encoder(waveform)  \n",
    "        print(f\"  [DEBUG] Encoded shape: {z.shape}\")\n",
    "\n",
    "        z_t = z.squeeze(0).permute(1, 0).cpu().numpy() \n",
    "        print(f\"  [DEBUG] Flattened shape: {z_t.shape}\")\n",
    "\n",
    "        z_t = subsample_latent(z_t, max_frames=3000)\n",
    "        print(f\"  [DEBUG] After subsampling: {z_t.shape}\")\n",
    "\n",
    "        embedded = spectral_embedding_eigengap(\n",
    "            z_t, k_max=5, sigma=1.0, maxiter=5000, tol=1e-2\n",
    "        )\n",
    "        print(\"  [DEBUG] Spectral embedding complete.\")\n",
    "\n",
    "        labels, chosen_k = auto_agglomerative(embedded, k_min=2, k_max=5)\n",
    "        print(f\"[INFO] Agglomerative => final cluster count = {chosen_k}\")\n",
    "\n",
    "        out_dir = output_root / Path(fname).stem\n",
    "        out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        z_original = z.clone()\n",
    "        T_sub = embedded.shape[0]\n",
    "        T_full = z_original.shape[-1]\n",
    "\n",
    "        unique_labels = sorted(set(labels))\n",
    "\n",
    "        full_mask = torch.zeros((1, 1, T_full), dtype=torch.float, device=device)\n",
    "        cluster_index = 1\n",
    "        for c_label in unique_labels:\n",
    "            idx_c = np.where(labels == c_label)[0]\n",
    "            mask = full_mask.clone()\n",
    "\n",
    "            for i_c in idx_c:\n",
    "                if i_c < T_full:\n",
    "                    mask[0, 0, i_c] = 1.0\n",
    "\n",
    "            z_masked = z_original * mask\n",
    "            separated_waveform = decoder(z_masked).squeeze(0)\n",
    "\n",
    "            out_path = out_dir / f\"source_{cluster_index}.wav\"\n",
    "            torchaudio.save(str(out_path), separated_waveform.cpu(), 44100)\n",
    "            print(f\"  [DEBUG] Saved cluster_{cluster_index} (label={c_label}) -> {out_path}\")\n",
    "            cluster_index += 1\n",
    "\n",
    "        entropies = compute_cluster_entropy(separated_signals, sample_rate=44100)\n",
    "        sparsities = compute_cluster_sparsity(separated_signals, sample_rate=44100)\n",
    "\n",
    "        for i, (H, S) in enumerate(zip(entropies, sparsities), start=1):\n",
    "            print(f\"[INFO] Cluster {i} Entropy: {H:.4f} | Sparsity: {S:.4f}\")\n",
    "\n",
    "        energy_ratios, sum_of_ratios, total_mix_energy = compute_energy_distribution(separated_signals, mix)\n",
    "\n",
    "        print(f\"\\n[INFO] Energy Distribution for {fname}:\")\n",
    "        print(f\"  Mixture energy = {total_mix_energy:.2f}\")\n",
    "        for i, ratio in enumerate(energy_ratios, start=1):\n",
    "            print(f\"  Cluster {i} => {ratio*100:.2f}% of mixture energy\")\n",
    "        print(f\"  Sum of ratios = {sum_of_ratios:.3f} (ideally ~1.0)\")\n",
    "\n",
    "        print(f\"[INFO] Done with {fname}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN clustering\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spla\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_laplacian(data, sigma=1.0, mode='rbf'):\n",
    "    dist = pairwise_distances(data, data, metric='euclidean')\n",
    "    if mode == 'rbf':\n",
    "        W = np.exp(-dist**2 / (2.0 * sigma**2))\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only RBF kernel is implemented.\")\n",
    "    d = np.sum(W, axis=1)\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(d + 1e-12))\n",
    "    W_tilde = D_inv_sqrt @ W @ D_inv_sqrt\n",
    "    L = np.eye(W.shape[0]) - W_tilde\n",
    "    return L\n",
    "\n",
    "def spectral_embedding_eigengap(data, k_max=5, sigma=1.0, maxiter=3000, tol=1e-3):\n",
    "    \"\"\"\n",
    "    Return a spectral embedding (dim chosen by largest eigen-gap).\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    if N <= k_max:\n",
    "        return data\n",
    "\n",
    "    L = compute_laplacian(data, sigma=sigma, mode='rbf')\n",
    "    L_sparse = sp.csr_matrix(L)\n",
    "\n",
    "    try:\n",
    "        eigenvals, eigenvects = spla.eigsh(\n",
    "            L_sparse, k=k_max+1, which='SM',\n",
    "            maxiter=maxiter, tol=tol,\n",
    "            ncv=min(2*(k_max+1), N)\n",
    "        )\n",
    "    except spla.ArpackNoConvergence as e:\n",
    "        print(f\"[WARNING] ARPACK failed to converge: {e}\")\n",
    "        return data\n",
    "\n",
    "    idx_sorted = np.argsort(eigenvals)\n",
    "    eigenvals = eigenvals[idx_sorted]\n",
    "    eigenvects = eigenvects[:, idx_sorted]\n",
    "\n",
    "    lam_nontrivial = eigenvals[1:]\n",
    "    gaps = np.diff(lam_nontrivial)\n",
    "    i_gap = np.argmax(gaps)\n",
    "    chosen_dim = i_gap + 1\n",
    "    chosen_dim = max(2, min(chosen_dim, k_max))\n",
    "\n",
    "    embedding = eigenvects[:, 1:1+chosen_dim]\n",
    "    return embedding\n",
    "\n",
    "def dbscan_only(embedded_data, eps_list=None, min_samples_list=None):\n",
    "    \"\"\"\n",
    "    Attempt DBSCAN with combinations of (eps, min_samples).\n",
    "    Pick the result with the largest number of clusters (excluding noise).\n",
    "    If zero clusters, fallback to a single cluster.\n",
    "\n",
    "    Returns:\n",
    "        best_labels: np.array of shape [N]\n",
    "        best_n_clusters: int (the number of clusters excluding noise, or 1 if fallback)\n",
    "    \"\"\"\n",
    "    if eps_list is None:\n",
    "        eps_list = [1.0, 0.7, 0.5, 0.3, 0.1]\n",
    "    if min_samples_list is None:\n",
    "        min_samples_list = [5, 10, 20]\n",
    "\n",
    "    best_labels = None\n",
    "    best_n_clusters = 0\n",
    "    best_settings = (None, None)\n",
    "\n",
    "    for eps in eps_list:\n",
    "        for ms in min_samples_list:\n",
    "            print(f\"[DEBUG] Trying DBSCAN with eps={eps}, min_samples={ms}\")\n",
    "            db = DBSCAN(eps=eps, min_samples=ms)\n",
    "            labels = db.fit_predict(embedded_data)\n",
    "\n",
    "            cluster_labels = set(labels) - {-1}\n",
    "            n_clusters = len(cluster_labels)\n",
    "            print(f\"   => Found {n_clusters} clusters (excluding noise).\")\n",
    "\n",
    "            if n_clusters > best_n_clusters:\n",
    "                best_labels = labels\n",
    "                best_n_clusters = n_clusters\n",
    "                best_settings = (eps, ms)\n",
    "\n",
    "    # print(f\"[INFO] Best DBSCAN => {best_n_clusters} cluster(s) with eps={best_settings[0]}, min_samples={best_settings[1]}.\")\n",
    "\n",
    "    if best_n_clusters == 0:\n",
    "        print(\"[WARNING] DBSCAN found 0 clusters. Fallback to 1 cluster (everything).\")\n",
    "        N = embedded_data.shape[0]\n",
    "        best_labels = np.zeros(N, dtype=int)  \n",
    "        best_n_clusters = 1\n",
    "\n",
    "    return best_labels, best_n_clusters\n",
    "\n",
    "def subsample_latent(z_t, max_frames=3000):\n",
    "    T_enc = z_t.shape[0]\n",
    "    if T_enc > max_frames:\n",
    "        idxs = np.linspace(0, T_enc - 1, max_frames, dtype=int)\n",
    "        z_t = z_t[idxs]\n",
    "    return z_t\n",
    "\n",
    "def reconstruction_loss(original_mixture, separated_sources):\n",
    "    \"\"\"\n",
    "    original_mixture: shape [channels, time] (or [time,])\n",
    "    separated_sources: list of Tensors each of shape [channels, time]\n",
    "    Returns scalar MSE between original_mixture and sum of separated_sources.\n",
    "    \"\"\"\n",
    "    if not separated_sources:\n",
    "        return torch.tensor(0.0, device=original_mixture.device)\n",
    "\n",
    "    summed_sources = torch.stack(separated_sources, dim=0).sum(dim=0)\n",
    "    return F.mse_loss(summed_sources, original_mixture)\n",
    "\n",
    "output_root = Path(\"separated_sources_dbscan_only\")\n",
    "output_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in dataloader:\n",
    "        waveform, fname = batch_data\n",
    "        if isinstance(fname, (list, tuple)):\n",
    "            fname = fname[0]\n",
    "\n",
    "        print(\"\\n=============================================\")\n",
    "        print(f\"[INFO] Processing file: {fname}\")\n",
    "\n",
    "        waveform = waveform.to(device)\n",
    "        if waveform.shape[1] == 1:\n",
    "            waveform = waveform.repeat(1, 2, 1)  \n",
    "\n",
    "        z = encoder(waveform) \n",
    "        print(f\"  [DEBUG] Encoded shape: {z.shape}\")\n",
    "\n",
    "        z_t = z.squeeze(0).permute(1, 0).cpu().numpy()\n",
    "        print(f\"  [DEBUG] Flattened shape: {z_t.shape}\")\n",
    "\n",
    "        z_t = subsample_latent(z_t, max_frames=3000)\n",
    "        print(f\"  [DEBUG] After subsampling: {z_t.shape}\")\n",
    "\n",
    "        embedded = spectral_embedding_eigengap(z_t, k_max=5, sigma=1.0, maxiter=5000, tol=1e-2)\n",
    "        print(\"  [DEBUG] Spectral embedding complete.\")\n",
    "\n",
    "        labels, chosen_k = dbscan_only(embedded, eps_list=[1.0, 0.7, 0.5, 0.3, 0.1],\n",
    "                                       min_samples_list=[5, 10, 20])\n",
    "        print(f\"[INFO] DBSCAN => final cluster count = {chosen_k}\")\n",
    "\n",
    "        out_dir = output_root / Path(fname).stem\n",
    "        out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        z_original = z.clone()  \n",
    "        T_full = z_original.shape[-1]\n",
    "\n",
    "        if chosen_k > 1:\n",
    "            unique_labels = sorted(set(labels) - {-1})\n",
    "        else:\n",
    "            unique_labels = sorted(set(labels))\n",
    "\n",
    "        if not unique_labels:\n",
    "            print(\"[WARNING] All points were noise. Forcing single cluster output.\")\n",
    "            unique_labels = [0]\n",
    "            labels = np.zeros_like(labels)  \n",
    "\n",
    "        separated_signals = []\n",
    "        cluster_index = 1\n",
    "\n",
    "        mix = waveform.squeeze(0) \n",
    "\n",
    "        full_mask = torch.zeros((1, 1, T_full), dtype=torch.float, device=device)\n",
    "        for c_label in unique_labels:\n",
    "            idx_c = np.where(labels == c_label)[0]\n",
    "            mask = full_mask.clone()\n",
    "\n",
    "            for i_c in idx_c:\n",
    "                if i_c < T_full:\n",
    "                    mask[0, 0, i_c] = 1.0\n",
    "\n",
    "            z_masked = z_original * mask\n",
    "            separated_waveform = decoder(z_masked).squeeze(0)  \n",
    "\n",
    "            if separated_waveform.shape[-1] > mix.shape[-1]:\n",
    "                separated_waveform = separated_waveform[..., :mix.shape[-1]]\n",
    "            elif separated_waveform.shape[-1] < mix.shape[-1]:\n",
    "                diff = mix.shape[-1] - separated_waveform.shape[-1]\n",
    "                separated_waveform = torch.nn.functional.pad(\n",
    "                    separated_waveform, (0, diff)\n",
    "                )\n",
    "\n",
    "            separated_signals.append(separated_waveform)\n",
    "\n",
    "            out_path = out_dir / f\"source_{cluster_index}.wav\"\n",
    "            torchaudio.save(str(out_path), separated_waveform.cpu(), 44100)\n",
    "            print(f\"  [DEBUG] Saved cluster_{cluster_index} (label={c_label}) -> {out_path}\")\n",
    "\n",
    "            cluster_index += 1\n",
    "\n",
    "        entropies = compute_cluster_entropy(separated_signals, sample_rate=44100)\n",
    "        sparsities = compute_cluster_sparsity(separated_signals, sample_rate=44100)\n",
    "\n",
    "        for i, (H, S) in enumerate(zip(entropies, sparsities), start=1):\n",
    "            print(f\"[INFO] Cluster {i} Entropy: {H:.4f} | Sparsity: {S:.4f}\")\n",
    "\n",
    "        energy_ratios, sum_of_ratios, total_mix_energy = compute_energy_distribution(separated_signals, mix)\n",
    "\n",
    "        print(f\"\\n[INFO] Energy Distribution for {fname}:\")\n",
    "        print(f\"  Mixture energy = {total_mix_energy:.2f}\")\n",
    "        for i, ratio in enumerate(energy_ratios, start=1):\n",
    "            print(f\"  Cluster {i} => {ratio*100:.2f}% of mixture energy\")\n",
    "        print(f\"  Sum of ratios = {sum_of_ratios:.3f} (ideally ~1.0)\")\n",
    "            \n",
    "        if separated_signals:\n",
    "            loss_val = reconstruction_loss(mix, separated_signals)\n",
    "            print(f\"[INFO] Reconstruction MSE for {fname}: {loss_val.item()}\")\n",
    "\n",
    "        print(f\"[INFO] Done with {fname}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
